{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Spark RDD from a text file, and spliting text with flatMap() operation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in splited text: 961114\n"
     ]
    }
   ],
   "source": [
    "raw_data = sc.textFile(\"shakespear_text.txt\")\n",
    "splited_text = raw_data.flatMap(lambda x : x.split())\n",
    "print(\"Total number of words in splited text:\",splited_text.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating w stop words set for later deletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of text for counting words:\n",
    "# 1. Filtering data with stop_words set.\n",
    "# 2. Creating a tuple for each word with its count = 1: a key - value tuples.\n",
    "# 3. Counting of words with reduceByKey() - transformation combines values (adding word count) with same key.\n",
    "# 4. Swaping keys and values inside tuples for sorting.\n",
    "# 5. Sorting RDD to obtain words with highest count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_no_stop_words = splited_text.filter(lambda x: x.lower() not in stop_words)\n",
    "word_tuples = text_no_stop_words.map(lambda w: (w,1))\n",
    "result = word_tuples.reduceByKey(lambda x,y: x + y)\n",
    "result_swap = result.map(lambda x: (x[1],x[0]))                                     \n",
    "result_sort = result_swap.sortByKey(ascending = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing 10 most frequent words in text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thou has 4514 counts\n",
      "thy has 3918 counts\n",
      "shall has 3248 counts\n",
      "good has 2169 counts\n",
      "would has 2133 counts\n",
      "Enter has 2005 counts\n",
      "thee has 1888 counts\n",
      "hath has 1720 counts\n",
      "like has 1642 counts\n",
      "you, has 1568 counts\n"
     ]
    }
   ],
   "source": [
    "for word in result_sort.take(10):\n",
    "    print(\"{} has {} counts\".format(word[1],word[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
